---
trigger: manual
---
# Testing Rules for {{project.name}}

> Testing patterns and conventions for AI-assisted development

## Testing Framework

{{#if detection.testing.[0]}}
- **Primary Framework**: {{detection.testing.[0].name}}
{{else}}
- **Framework**: To be configured
{{/if}}

## Test Organization

### File Structure

```
{{#if (eq project.language "typescript")}}
src/
  feature/
    index.ts
    index.test.ts    # Co-located tests
tests/
  integration/       # Integration tests
  e2e/               # End-to-end tests
{{else if (eq project.language "python")}}
src/
  feature/
    __init__.py
    module.py
tests/
  unit/              # Unit tests
  integration/       # Integration tests
  conftest.py        # Shared fixtures
{{else}}
src/
  feature/
tests/
  unit/
  integration/
{{/if}}
```

### Naming Conventions

- Test files: `*.test.{ts,js}` or `*.spec.{ts,js}`
- Test suites: Describe the module or function being tested
- Test cases: Use descriptive names that explain the scenario

## Writing Tests

### Test Structure

Follow the Arrange-Act-Assert pattern:

{{#if (eq project.language "typescript")}}
```typescript
describe('functionName', () => {
  it('should return expected result when given valid input', () => {
    // Arrange
    const input = { /* test data */ };

    // Act
    const result = functionName(input);

    // Assert
    expect(result).toEqual(expected);
  });
});
```
{{else if (eq project.language "python")}}
```python
def test_function_returns_expected_when_valid_input():
    # Arrange
    input_data = {"key": "value"}

    # Act
    result = function_name(input_data)

    # Assert
    assert result == expected
```
{{else}}
```javascript
describe('functionName', () => {
  it('should return expected result when given valid input', () => {
    // Arrange
    const input = { /* test data */ };

    // Act
    const result = functionName(input);

    // Assert
    expect(result).toEqual(expected);
  });
});
```
{{/if}}

### Best Practices

1. **Test one thing per test** - Each test should verify a single behavior
2. **Use descriptive names** - Test names should explain what's being tested
3. **Avoid test interdependence** - Tests should run independently
4. **Mock external dependencies** - Isolate the unit being tested
5. **Test edge cases** - Include boundary conditions and error cases

### What to Test

- **Unit Tests**: Individual functions and methods
- **Integration Tests**: Component interactions
- **Error Cases**: Invalid inputs, network failures, edge cases
- **Business Logic**: Core domain rules and calculations

### What Not to Test

- Implementation details that may change
- Third-party library internals
- Simple getters/setters without logic
- Framework code that's already tested

## Mocking Guidelines

{{#if (eq project.language "typescript")}}
- Use `jest.mock()` or `vi.mock()` for module mocking
- Prefer dependency injection for easier testing
- Reset mocks between tests with `beforeEach`
- Avoid over-mocking - test real integrations when practical
{{else if (eq project.language "python")}}
- Use `unittest.mock` or `pytest-mock` for mocking
- Prefer dependency injection for easier testing
- Use fixtures for shared test setup
- Avoid over-mocking - test real integrations when practical
{{else}}
- Use appropriate mocking library for your test framework
- Prefer dependency injection for easier testing
- Reset mocks between tests
- Avoid over-mocking - test real integrations when practical
{{/if}}

## Test Quality Checklist

- [ ] Tests are independent and can run in any order
- [ ] Test names clearly describe the scenario
- [ ] Edge cases and error conditions are covered
- [ ] Mocks are used appropriately
- [ ] No flaky tests (random failures)
- [ ] Tests run quickly (< 100ms for unit tests)

---
*Generated by AIde v{{generated.version}}*
